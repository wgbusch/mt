{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento de dígitos con KNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los path al ejecutable de python 3.6 y sus librerías,\n",
    "de acuerdo al virtual env que estén corriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘build’: File exists\n",
      "-- The C compiler identification is GNU 9.3.0\n",
      "-- The CXX compiler identification is GNU 9.3.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc - works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "Release mode\n",
      "-- Found PythonInterp: /home/jazzer/.pyenv/versions/3.6.5/bin/python (found version \"3.6.5\") \n",
      "-- Found PythonLibs: /home/jazzer/.pyenv/versions/3.6.5/lib/libpython3.6m.a\n",
      "-- pybind11 v2.2.4\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "CMAKE_INSTALL_PREFIX=/home/jazzer/Facultad/metodos_numericos/mt/tp2\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/jazzer/Facultad/metodos_numericos/mt/tp2/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target tp2\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/main.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/eigen.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX executable tp2\u001b[0m\n",
      "[ 50%] Built target tp2\n",
      "\u001b[35m\u001b[1mScanning dependencies of target metnum\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/metnum.dir/src/metnum.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/metnum.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/metnum.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/metnum.dir/src/eigen.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module metnum.cpython-36m-x86_64-linux-gnu.so\u001b[0m\n",
      "[100%] Built target metnum\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /home/jazzer/Facultad/metodos_numericos/mt/tp2/notebooks/metnum.cpython-36m-x86_64-linux-gnu.so\n",
      "/home/jazzer/Facultad/metodos_numericos/mt/tp2/notebooks\n",
      "Python 3.6.5\n"
     ]
    }
   ],
   "source": [
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install\n",
    "\n",
    "# Verifico la correcta instalación. Si no falla el import está OK\n",
    "!pwd\n",
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Ahora tengo 26880 instancias de entrenamiento y 6720 de validación\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import metnum as mt\n",
    "import datetime\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from numpy import savetxt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#percentage over total of train cases\n",
    "PERCENTAGE_OF_TRAIN_CASES = 0.8\n",
    "#neighbors for finding the mode in KNN\n",
    "N_NEIGHBORS = 100\n",
    "#components for PCA\n",
    "N_COMPONENTS=40\n",
    "#number of iterations to find eigenvalues and eigenvectors in power iteration\n",
    "N_ITERATIONS=5000\n",
    "#epsilon for power iteration\n",
    "EPSILON=1e-10\n",
    "#directory for saving matrix files\n",
    "timestamp = datetime.now().strftime(\"%m_%d_%H_%M_%S\")\n",
    "DIRECTORY_NAME=\"{}\".format(timestamp)\n",
    "os.makedirs(DIRECTORY_NAME+\"/\", exist_ok=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "TOTAL_TRAIN_CASES = int(PERCENTAGE_OF_TRAIN_CASES*len(df_train))\n",
    "\n",
    "#shuffle the train cases.\n",
    "df_train = df_train[0: TOTAL_TRAIN_CASES].sample(frac=1)\n",
    "\n",
    "# Uso values para mandar todo a arrays de numpy\n",
    "X = df_train[df_train.columns[1:]].values\n",
    "y = df_train[\"label\"].values.reshape(-1, 1)\n",
    "\n",
    "limit = int(0.8 * X.shape[0]) \n",
    "\n",
    "X_train, y_train = X[:limit], y[:limit]\n",
    "X_val, y_val = X[limit:], y[limit:]\n",
    "\n",
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_val) == len(y_val)\n",
    "\n",
    "print(f\"Ahora tengo {len(X_train)} instancias de entrenamiento y {len(X_val)} de validación\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcional: guardamos las matrices de entrenamiento en un archivo si queremos reproducir el experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('{}/X_train.csv'.format(DIRECTORY_NAME), X_train, delimiter=',')\n",
    "savetxt('{}/y_train.csv'.format(DIRECTORY_NAME), y_train, delimiter=',')\n",
    "savetxt('{}/X_val.csv'.format(DIRECTORY_NAME), X_val, delimiter=',')\n",
    "savetxt('{}/y_val.csv'.format(DIRECTORY_NAME), y_val, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing sin PCA (raw data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el dato con los test cases sin modificar y probamos su accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9202380952380952\n",
      "CPU times: user 7min 13s, sys: 1.21 s, total: 7min 14s\n",
      "Wall time: 7min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = mt.KNNClassifier(N_NEIGHBORS)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val[0:])\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy: {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo para probar la capacidad del modelo a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  12 235 234  86   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  89 252 252 142   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  14 100 100\n",
      "  147 124 224 252 252  84   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1  90 166 242 245 252 252\n",
      "  252 252 252 252 152   3   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  44 160 252 252 252 222 212 252\n",
      "  252 252 252 226  77   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  20 169 252 252 187 117  24  15 218\n",
      "  252 252 252 179   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 156 252 252 183  34   0   2 118 249\n",
      "  252 221 131  21   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 165 252 252 235 121  45 120 252 252\n",
      "  171  34   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  67 236 252 252 252 252 253 232 175\n",
      "   36   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  26 138 252 252 252 239 106   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  26 253 253 253 255 196  21\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  62 213 252 252 146 196 252 106\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 137 224 252 252  98   6  21 222 106\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   9 185 249 252 174  10   3   0  42 249  48\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 124 252 252 170   8   0   0   0 120 238  82\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  53 243 252 194  36   0   0   0  39 253 238  34\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 120 252 252  88   4  12  79 155 240 252 212  23\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 176 252 252 117 165 252 252 252 233 134   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 176 252 252 252 252 252 205 175  51   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  23 124 248 180 142 137  13   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Prediction: 8 - Digit: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_example= 598\n",
    "\n",
    "img = X_val[random_example].reshape(28, 28)\n",
    "plt.imshow(img, cmap=\"Greys\")\n",
    "\n",
    "print(img)\n",
    "\n",
    "print(\"Prediction: {} - Digit: {}\".format( int(y_pred[random_example]), int(y_val[random_example])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing con PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usamos PCA para transformar la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pca = mt.PCA(N_COMPONENTS, N_ITERATIONS, EPSILON)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_pca, X_val_pca = pca.transform(X_train), pca.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opcional: guardamos las matrices de entrenamiento en un archivo si queremos reproducir el experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savetxt('{}/X_train_pca.csv'.format(DIRECTORY_NAME), X_train_pca, delimiter=',')\n",
    "savetxt('{}/X_val_pca.csv'.format(DIRECTORY_NAME), X_val_pca, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos el modelo con la data de PCA y testeamos accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = mt.KNNClassifier(N_NEIGHBORS)\n",
    "\n",
    "clf.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_val_pca[0:])\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testeo automático moviendo parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable range: {'range': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
      "       35, 36, 37, 38, 39]), 'name': 'N_NEIGHBORS'}\n",
      "Fixed variables:[{'name': 'N_COMPONENTS', 'value': 20}, {'name': 'PERCENTAGE_OF_TRAIN_CASES', 'value': 0.7}, {'name': 'N_ITERATIONS', 'value': 2000}, {'name': 'EPSILON', 'value': 1e-10}]\n",
      "PERCENTAGE_OF_TRAIN_CASES : 0.7\n",
      "N_NEIGHBORS : 1\n",
      "N_COMPONENTS : 20\n",
      "N_ITERATIONS : 2000\n",
      "EPSILON : 1e-10\n",
      "\n",
      "PERCENTAGE_OF_TRAIN_CASES : 0.7\n",
      "N_NEIGHBORS : 2\n",
      "N_COMPONENTS : 20\n",
      "N_ITERATIONS : 2000\n",
      "EPSILON : 1e-10\n",
      "\n",
      "PERCENTAGE_OF_TRAIN_CASES : 0.7\n",
      "N_NEIGHBORS : 3\n",
      "N_COMPONENTS : 20\n",
      "N_ITERATIONS : 2000\n",
      "EPSILON : 1e-10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import metnum as mt\n",
    "import datetime\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from numpy import savetxt\n",
    "from sklearn.metrics import *\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def calculate_metrics(y_val, y_pred, time):\n",
    "    \n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, average=None)\n",
    "    recall = recall_score(y_val, y_pred, average=None)\n",
    "    f1 = f1_score(y_val, y_pred, average=None)\n",
    "    kappa = -1#kappa_score(y_val, y_pred, average=None)\n",
    "    \n",
    "    return (acc, precision, recall, \n",
    "            f1, kappa, time)\n",
    "\n",
    "def experiment_generic(variables, pca, seed):\n",
    "    \n",
    "    for variable in variables:\n",
    "        name = variable[\"name\"]\n",
    "        value = variable[\"value\"]\n",
    "        if(name==\"PERCENTAGE_OF_TRAIN_CASES\"):\n",
    "            PERCENTAGE_OF_TRAIN_CASES = value\n",
    "        elif (name==\"N_NEIGHBORS\"):\n",
    "            N_NEIGHBORS = value\n",
    "        elif (name==\"N_COMPONENTS\"):\n",
    "            N_COMPONENTS = value\n",
    "        elif (name == \"N_ITERATIONS\"):\n",
    "            N_ITERATIONS = value\n",
    "        elif(name == \"EPSILON\"):\n",
    "            EPSILON = value\n",
    "            \n",
    "    print(\"{} : {}\\n{} : {}\\n{} : {}\\n{} : {}\\n{} : {}\\n\".format(\"PERCENTAGE_OF_TRAIN_CASES\",PERCENTAGE_OF_TRAIN_CASES,\n",
    "                                                                 \"N_NEIGHBORS\",N_NEIGHBORS,\n",
    "                                                                 \"N_COMPONENTS\",N_COMPONENTS,\n",
    "                                                                 \"N_ITERATIONS\",N_ITERATIONS,\n",
    "                                                                 \"EPSILON\",EPSILON))\n",
    "    return experiment(PERCENTAGE_OF_TRAIN_CASES, \n",
    "                   N_NEIGHBORS, \n",
    "                   N_COMPONENTS, \n",
    "                   N_ITERATIONS, \n",
    "                   EPSILON,\n",
    "                   pca,\n",
    "                   seed)\n",
    "    \n",
    "    \n",
    "def experiment(PERCENTAGE_OF_TRAIN_CASES, \n",
    "                   N_NEIGHBORS, \n",
    "                   N_COMPONENTS, \n",
    "                   N_ITERATIONS, \n",
    "                   EPSILON,\n",
    "                   pca,\n",
    "                   seed):\n",
    "    \n",
    "    start = time.time()\n",
    "    df_train = pd.read_csv(\"../data/train.csv\")\n",
    "    \n",
    "    TOTAL_TRAIN_CASES = int(PERCENTAGE_OF_TRAIN_CASES*len(df_train))\n",
    "    \n",
    "    #shuffle the train cases.\n",
    "    df_train = df_train[0:].sample(frac=1, random_state=seed)\n",
    "    \n",
    "    # Uso values para mandar todo a arrays de numpy\n",
    "    X = df_train[df_train.columns[1:]].values\n",
    "    y = df_train[\"label\"].values.reshape(-1, 1)\n",
    "    \n",
    "    X_train, y_train = X[:TOTAL_TRAIN_CASES], y[:TOTAL_TRAIN_CASES]\n",
    "    X_val, y_val = X[TOTAL_TRAIN_CASES:], y[TOTAL_TRAIN_CASES:]\n",
    "    \n",
    "    if(pca):\n",
    "        pca = mt.PCA(N_COMPONENTS, N_ITERATIONS, EPSILON)\n",
    "        pca.fit(X_train)\n",
    "\n",
    "        X_train, X_val = pca.transform(X_train), pca.transform(X_val)\n",
    "\n",
    "    \n",
    "    clf = mt.KNNClassifier(N_NEIGHBORS)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_val[0:])\n",
    "    \n",
    "    return calculate_metrics(y_val, y_pred, time.time()-start)\n",
    "\n",
    "\n",
    "def create_df(variable, experiment_results):\n",
    "    df = pd.DataFrame(columns=[variable, 'ACCURACY', 'TIME'])\n",
    "    \n",
    "    for i in range(10):\n",
    "        df['PRECISION_'+str(i)] = np.NaN\n",
    "    for i in range(10):\n",
    "        df['RECALL_'+str(i)] = np.NaN\n",
    "    for i in range(10):\n",
    "        df['F1_'+str(i)] = np.NaN\n",
    "        \n",
    "    return df.append(experiment_results, sort=False)\n",
    "\n",
    "\n",
    "def experiment_generic_move_variable(variable_range, fixed_variables, seed, pca=1):\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%m-%d-%H-%M-%S\")\n",
    "    \n",
    "    experiment_results = []\n",
    "    \n",
    "    NAME_OF_VARIABLE = variable_range[\"name\"]\n",
    "    print(\"variable range: \"+str(variable_range)+\"\\nFixed variables:\"+str(fixed_variables))\n",
    "    \n",
    "    for value in variable_range[\"range\"]:\n",
    "        fixed_variables.append({\"name\":NAME_OF_VARIABLE, \"value\":value})\n",
    "        \n",
    "        (acc, precision, recall, \n",
    "        f1, kappa, execution_time) =  experiment_generic(fixed_variables, pca, seed)\n",
    "        \n",
    "        data = {\n",
    "            NAME_OF_VARIABLE : value,\n",
    "            'ACCURACY' : acc,\n",
    "            'TIME' : round(execution_time)\n",
    "        }\n",
    "        \n",
    "        for i in range(10):\n",
    "            data['PRECISION_'+str(i)] = precision[i]\n",
    "            data['RECALL_'+str(i)] = recall[i]\n",
    "            data['F1_'+str(i)] = f1[i]\n",
    "            \n",
    "        experiment_results.append(data)\n",
    "        \n",
    "    filename='test_'+NAME_OF_VARIABLE+'-{}'.format(time.time())\n",
    "    \n",
    "    df_result = create_df(NAME_OF_VARIABLE, experiment_results)  \n",
    "    df_result.to_csv(filename+'.csv', encoding='utf-8', index=False)\n",
    "    \n",
    "    metadata = {\n",
    "        'TIMESTAMP' : [timestamp],\n",
    "        'SEED' : [seed]\n",
    "    }\n",
    "    \n",
    "    metadata_columns = ['TIMESTAMP', 'SEED']\n",
    "    \n",
    "    for fixed_variable in fixed_variables:\n",
    "        metadata[fixed_variable[\"name\"]] = fixed_variable[\"value\"]\n",
    "        metadata_columns.append(fixed_variable[\"name\"])\n",
    "                \n",
    "    df_metadata = pd.DataFrame(metadata, columns = metadata_columns)\n",
    "    df_metadata.to_csv(filename+'-metadata.csv',encoding = 'utf-8', index=False)\n",
    "    \n",
    "    display(df_metadata)\n",
    "    display(df_result)\n",
    "\n",
    "        \n",
    "def main():\n",
    "    #percentage over total of train cases\n",
    "    PERCENTAGE_OF_TRAIN_CASES = 0.7\n",
    "    #neighbors for finding the mode in KNN\n",
    "    N_NEIGHBORS = 20\n",
    "    #components for PCA\n",
    "    N_COMPONENTS=20\n",
    "    #number of iterations to find eigenvalues and eigenvectors in power iteration\n",
    "    N_ITERATIONS=2000\n",
    "    #epsilon for power iteration\n",
    "    EPSILON=1e-10\n",
    "    seed=394\n",
    "\n",
    "    \n",
    "    experiment_generic_move_variable({\"range\" : np.arange(1,40,1), \n",
    "                                      \"name\" : \"N_NEIGHBORS\"},\n",
    "                                    [{\"name\":\"N_COMPONENTS\",\"value\":N_COMPONENTS},\n",
    "                                     {\"name\":\"PERCENTAGE_OF_TRAIN_CASES\",\"value\":PERCENTAGE_OF_TRAIN_CASES},\n",
    "                                     {\"name\":\"N_ITERATIONS\",\"value\":N_ITERATIONS},\n",
    "                                     {\"name\":\"EPSILON\",\"value\":EPSILON}], \n",
    "                                     seed, \n",
    "                                     1)\n",
    "    \n",
    "    experiment_generic_move_variable({\"range\" : np.arange(1,40,1), \n",
    "                                      \"name\" : \"N_NEIGHBORS\"},\n",
    "                                    [{\"name\":\"N_COMPONENTS\",\"value\":N_COMPONENTS},\n",
    "                                     {\"name\":\"PERCENTAGE_OF_TRAIN_CASES\",\"value\":PERCENTAGE_OF_TRAIN_CASES},\n",
    "                                     {\"name\":\"N_ITERATIONS\",\"value\":N_ITERATIONS},\n",
    "                                     {\"name\":\"EPSILON\",\"value\":EPSILON}], \n",
    "                                     seed, \n",
    "                                     0)\n",
    "    \n",
    "#     experiment_generic_move_variable({\"range\" : np.arange(1,3,1), \n",
    "#                                       \"name\" : \"N_COMPONENTS\"}, \n",
    "#                                     [{\"name\":\"N_NEIGHBORS\",\"value\":N_NEIGHBORS}, \n",
    "#                                      {\"name\":\"PERCENTAGE_OF_TRAIN_CASES\",\"value\":PERCENTAGE_OF_TRAIN_CASES}, \n",
    "#                                      {\"name\":\"N_ITERATIONS\",\"value\":N_ITERATIONS}, \n",
    "#                                      {\"name\":\"EPSILON\",\"value\":EPSILON}], \n",
    "#                                      seed, \n",
    "#                                      1)\n",
    "    \n",
    "#     experiment_generic_move_variable({\"range\" : np.arange(0.1,1,0.1), \n",
    "#                                       \"name\" : \"PERCENTAGE_OF_TRAIN_CASES\"},\n",
    "#                                     [{\"name\":\"N_NEIGHBORS\",\"value\":N_NEIGHBORS},\n",
    "#                                      {\"name\":\"N_COMPONENTS\",\"value\":N_COMPONENTS},\n",
    "#                                      {\"name\":\"N_ITERATIONS\",\"value\":N_ITERATIONS},\n",
    "#                                      {\"name\":\"EPSILON\",\"value\":EPSILON}], \n",
    "#                                      seed, \n",
    "#                                      1)\n",
    "        \n",
    "#     experiment_generic_move_variable({\"range\" : np.arange(100,2000,100), \n",
    "#                                       \"name\" : \"N_ITERATIONS\"},\n",
    "#                                     [{\"name\":\"N_NEIGHBORS\",\"value\":N_NEIGHBORS},\n",
    "#                                      {\"name\":\"PERCENTAGE_OF_TRAIN_CASES\",\"value\":PERCENTAGE_OF_TRAIN_CASES},\n",
    "#                                      {\"name\":\"N_COMPONENTS\",\"value\":N_COMPONENTS},\n",
    "#                                      {\"name\":\"EPSILON\",\"value\":EPSILON}], \n",
    "#                                      seed, \n",
    "#                                      1)\n",
    "        \n",
    "#     experiment_generic_move_variable({\"range\" : np.arange(5,7,1), \n",
    "#                                       \"name\" : \"EPSILON\"},\n",
    "#                                     [{\"name\":\"N_NEIGHBORS\",\"value\":N_NEIGHBORS},\n",
    "#                                      {\"name\":\"PERCENTAGE_OF_TRAIN_CASES\",\"value\":PERCENTAGE_OF_TRAIN_CASES},\n",
    "#                                      {\"name\":\"N_ITERATIONS\",\"value\":N_ITERATIONS},\n",
    "#                                      {\"name\":\"N_COMPONENTS\",\"value\":N_COMPONENTS}], \n",
    "#                                      seed, \n",
    "#                                      1)\n",
    "    \n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
